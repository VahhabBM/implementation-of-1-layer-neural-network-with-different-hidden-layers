# implementation-of-1-layer-neural-network-with-different-hidden-layers
implementation of 1 layer neural network with different hidden layers on a planar dataset (binary classification) .

# 🧠 Single Layer Neural Network Implementation

This repository contains the implementation of a **Single Layer Neural Network** from scratch using **NumPy** and **Matplotlib**.  
It is based on the **Week 3 Assignment** from the Deep Learning Specialization by Andrew Ng.

---

## 📌 Project Description

The goal of this project is to implement a **binary classifier** for a planar dataset by training a neural network **without using any deep learning frameworks** such as TensorFlow or PyTorch.  
We use only **NumPy** for mathematical computations and **Matplotlib** for visualization.

The dataset is **non-linearly separable**, making it a great example to understand why logistic regression fails here and how a neural network can solve the problem.

---

## 📂 Repository Structure


├── 1 layer neural network implementation.py # Main implementation

├── planar_utils.py # Helper functions (dataset loading, plotting)

├── testCases_v2.py # Predefined test cases

├── README.md # Project description (this file)


---

## 🛠 Features

- Implementation of forward propagation and backward propagation **from scratch**.
- Gradient descent parameter update.
- Flexible number of neurons in the hidden layer.
- Visualization of the **decision boundary** with a **custom blue/red colormap**.
- Accuracy measurement for different hidden layer sizes.

---

## 📊 Dataset

We use a synthetic **planar dataset** loaded from `planar_utils.py`.  
Each point belongs to one of two classes, represented by:
- 🔵 **Blue points** → Class 0
- 🔴 **Red points** → Class 1

---

## 🚀 How to Run

just run the "1 layer neural network implementation.py" file to see the results for different hidden layers and their accuracy.

---
📈 Example Output
Decision Boundary Visualization
Below is an example of the decision boundary generated by the model:
<img width="942" height="1441" alt="image" src="https://github.com/user-attachments/assets/21acf2a7-d684-4207-b810-c77792cb4ffc" />

---

📚 Learning Points
- Through this project, you will:

- Understand how neural networks work internally.

- Learn how to implement forward & backward propagation.

- See how network capacity (hidden layer size) affects performance.

- Practice visualizing decision boundaries for classifiers.

---

📝 References
- Deep Learning Specialization - Andrew Ng (Coursera)

- NumPy Documentation

- Matplotlib Documentation





